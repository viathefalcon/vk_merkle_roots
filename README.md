# Vulkan Merkle Roots

## Summary
A program to demonstrate the calculation/resolution of the roots of [Merkle/hash trees](https://en.wikipedia.org/wiki/Merkle_tree) of arbitrary inputs on GPUs via the [Vulkan API](https://en.wikipedia.org/wiki/Vulkan).

## Components
### `vkmr`
This is the primary program; it reads inputs from `stdin` and then calculates their Merkle root, either serially on the CPU or in parallel on a selected compute-capable GPU reported by Vulkan.

### `strm`
This helper program accepts an arbitrary number of command-line arguments and writes them to a line-separated stream in `stdout`.

### `rndm`
This helper program generates a specified number of randomly-filled input strings and writes them to a line-separated stream in `stdout`.

## Building, Running
The Visual Studio Code project includes tasks which will build the programs; it assumes that either the Visual C++ compiler (on Windows) or Clang (elsewhere) is on the `PATH`.

### On (Steam) Deck
To build the project on Steam Deck, I run [VS Code in Flatpak](https://flathub.org/apps/com.visualstudio.code). For building, and running, on Steam Deck, the project has an implicit dependency on LLVM 18, which I satisfy with the [LLVM 18 extension for the flatpak Freedesktop SDK](https://github.com/flathub/org.freedesktop.Sdk.Extension.llvm18). I installed VS Code via the Discovery package manager, and the LLVM extension via the command-line:
```
flatpak install org.freedesktop.Sdk.Extension.llvm18
```

#### Launching VS Code
(and enabling the LLVM 18 extension)
```
FLATPAK_ENABLE_SDK_EXT=llvm18 flatpak run --devel com.visualstudio.code
```

#### Running the Program
The program, once built, also needs to run in a Flatpak container in which the LLVM 18 extension is available. So, I open a shell in the VS Code sandbox:
```
FLATPAK_ENABLE_SDK_EXT=llvm18 flatpak run --command=sh --devel com.visualstudio.code
```

And, inside this shell:
```
cd bin
./rndm.app 1712489279 1024 127 | ./vkmr.app
```

## Background
Initially, the goal was to investigate the practicality of using a GPU, as an asynchronous co-processor, to accelerate the generation of blockchain block headers; these will typically contain a hash representation of the block data, and this is often generated by computing the Merkle root of the records in the block.

Pulling a proof-of-concept together, using OpenCL, really wasn't too difficult, but iterating on it proved .. if not impossible then certainly impractical. The main sticking point was overcoming the requirement for a synchronous round trip between the host (CPU) and the accelerator (GPU) for each level of the tree. The specs for OpenCL 2.x+  provide a mechanism to avoid this - [Device-Side Enqueue](https://registry.khronos.org/OpenCL/specs/3.0-unified/html/OpenCL_API.html#device-side-enqueue) - but support for OpenCL across vendors and devices varied, to put it mildly, and I could only get device-side enqueueing to work on one (1) integrated Intel GPU. When I tried to code around this, using OpenCL ~1.2 and pushing as much of the conditional logic as I could into compute shaders, I ended up with [this hot mess](https://gist.github.com/viathefalcon/6d82a14214d6e4f7af29b75133ef6c16).

It was when I got a Steam Deck that I decided to reboot the project based on Vulkan (in part to have something for the Deck to do..)

## Design

### Goals
* Be able to compute the Merkle roots of arbitrary data sets entirely on GPU via parallel reduction;
* Not have any dependencies beyond Vulkan and the C++ Standard Library.

### Non-Goals
* Performance: where there is a choice between doing something on the GPU and doing it more performantly on the CPU, do it on the GPU (the aim being, recall, that the Merkle root calculation runs entirely asynchronously with respect to whatever's happening on the CPU).

### Choices

#### Hash Function

I chose [SHA-256d](https://bitcoinwiki.org/wiki/sha-256d), or double `SHA-256`, as the hash function because it is used in Bitcoin, and to spare myself the effort of evaluating different hash functions. Additionally, it has the agreeable property that the 256-bit/32-byte output is naturally aligned in most places that that matters.

`SHA-256d` outputs the result of applying the `SHA-256` algorithm to the result of applying `SHA-256` to the input.

#### Subgroups

Merkle root calculation generates a _lot_ of intermediate values that are ultimately discarded. We avoid writing many of those values to memory by using [Subgroups](https://docs.vulkan.org/guide/latest/subgroups.html) (where supported), such that instead of each reduction invocation taking a pair of inputs and writing a single output, groups of invocations reduce whole subtrees by sharing intermediate values and writing a single output. Using subgroups in this way also reduces the total number of dispatches needed to calculate the root of the sub-tree for any given slice.

### Basic Flow

The program implements a kind of stream processor. Inputs are read from a stream and accumulated into _batches_; once a given batch is full, or the end of the input stream has been reached, the batch is sent to the GPU to be mapped.

_Mapping_ comprises two operations: applying the hash function to inputs and writing the outputs to "device local" memory, which is divided into _slices_. Each such slice holds up to some power of 2 number of hashes, which comprise the leaves of the tree whose root we are looking to calculate, and all slices are the same size.

Once a given slice is full, or the end of the input stream has been reached, the slice is sent for _reduction_. Each reduction calculates the root of the sub-tree of the slice to which the reduction is applied. Once all reductions have concluded, the outputs from each are used to calculate (on the CPU, in contravention of the goals outlined above..) the root of the tree for which they are the leaves.

Once each mapping and reduction conclude, the memory associated with the the corresponding batch or slice is immediately returned to the system. Additionally, every mapping and reduction runs asynchronously with respect to every other mapping and reduction as well as reading of (any) subsequent inputs, and the program does not need to have read in the entire dataset before it can start calculating the Merkle root.